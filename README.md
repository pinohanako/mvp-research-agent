# MVP агента для работы с научными текстами

AI-ассистент использует долговременную и временную память для хранения сообщений и структурированных данных контекста, запросы перенаправляются с помощью LLM, настроена интеграция внешних источников для поиска научной информации. Ключевой компонент — **граф состояний**, который управляет обработкой пользовательских запросов, памятью и взаимодействием с внешними инструментами вроде arXiv и загруженным PDF. Граф позволяет циклически обрабатывать данные: например, анализ статьи -> поиск дополнительных фрагментов -> обновление суммаризации.

---

## Определение намерения

Намерение пользователя (`intent`) классифицируется на три категории:

- `qa` — прямой ответ на вопрос или свободный текст.
- `search` — поиск статей на arXiv.
- `analyze` — работа с уже загруженными статьями (анализ, суммаризация).

Для этого используется LLM через OpenAI/Fireworks API с Pydantic-парсером для строгой валидации JSON-ответа.

---

## Узлы

Система строится вокруг **графа узлов**, каждый из которых выполняет определённую функцию:

- `call_model` — определяет **намерение пользователя (intent)** и формирует данные для передачи.
- `store_memory` — сохраняет ключевые сообщения в долговременную память.
- `analyze_node` — анализирует выбранную статью, используя релевантные фрагменты из Qdrant.
- `arxiv_research` — выполняет поиск статей на arXiv по запросу.
- `summarize_sources` — агрегирует найденные статьи в промежуточную суммаризацию.
- `finalize_summary` — создает финальную суммаризацию с источниками.

Граф соединяет узлы **по условным ребрам**, поток данных в зависимости от текущего состояния и намерения пользователя.

---

## Организация памяти

### Долговременная память
- Сохраняет **подтвержденные статьи** и ключевые факты через `upsert_memory`.
- Хранится в **PostgreSQL** с TTL, интегрирована с StateGraph через `AsyncPostgresStore` и `AsyncPostgresSaver`.

### Временная исследовательская память
- Хранит результаты поиска и промежуточные суммаризации.
- Используется при цикличном поиске на arXiv (`research_loop_count`) и для генерации агрегированных ответов.

### Контекст пользователя
- Текущий запрос, намерение, выбранная статья (`current_article`) — в `PrivateState`.

Все состояния объединены в структуру `OverallState`, которая хранит историю диалога (`messages`) и временные данные, сформированные при поиске статей.

---

## Анализ и поиск

- **Анализ статьи** (`analyze_node`):
  - Получение embedding запроса через Jina.
  - Поиск релевантных чанков в **Qdrant**.
  - Конструирование промпта для LLM с учетом контекста статьи и найденных фрагментов.

- **Поиск на arXiv** (`arxiv_research`):
  - Запрос к API arXiv.
  - Извлечение найденных URL и сохранение текста в `raw_results`.
  - Итеративная суммаризация через `summarize_sources` и `finalize_summary`.

---

## Передача данных

- **Между узлами**: через `state` графа.
- **LLM ↔ память**: последние сообщения пользователя подтягиваются для контекста.
- **Результаты поиска** → суммаризация → LLM для генерации ответа.

Все данные структурированы в JSON/Pydantic-моделях (`Intent`, `Filter`, `ArticleInfo`) для строгой типизации и извлечения нужной информации.

---

## Мониторинг

Встроенный **логгер** фиксирует события на каждом узле.

**Langfuse** используется для трассировки вызовов функций (`@traced`) и мониторинга потоков данных.

TTL-сейвер следит за устаревшими записями в памяти и очищает их асинхронно.

---

## Используемые технологии

**LLM**: OpenAI / Fireworks API

**Vector Store**: Qdrant

**Долговременная память**: PostgreSQL (AsyncPostgresStore, AsyncPostgresSaver)

**PDF обработка**: SpaCy + spacypdfreader

**Разделение текста**: RecursiveCharacterTextSplitter

**Граф состояний**: langgraph (StateGraph, Runtime)

**Трассировка и мониторинг**: langfuse

**Схемы данных и парсинг**: Pydantic
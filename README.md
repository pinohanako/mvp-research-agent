# MVP агента для работы с научными текстами

Долговременная и временная память используется для хранения сообщений и структурированных данных, извлеченных из контекста по мере диалога; запросы перенаправляются с помощью LLM, настроена интеграция внешних источников для поиска научной информации 

Ключевой компонент — **граф состояний**, который управляет обработкой пользовательских запросов

<p align="center">
  <img src="https://github.com/pinohanako/mvp-research-agent/blob/main/agent/docs/GraphLangsmith.png" alt="Прототип агента" width="700"/>
</p>

---

## Намерения пользователя

При каждом запросе LLM классифицирует намерение на три категории:

- `search` — поиск статей на arXiv
- `analyze` — работа с уже загруженными статьями (анализ, суммаризация)
- `qa` — прямой ответ на вопрос или свободный текст

Для валидации JSON-ответа используется Pydantic-парсер и StructuredOutput

Провайдер API: OpenAI/Fireworks

---

## `State`

- `messages` — список сообщений AnyMessage. Хранит историю диалога
- `query` — текущая строка запроса пользователя
- `intent` — распознанное текущее намерение: `"qa"` | `"search"` | `"analyze"`
- `current_article` — ArticleState (`title`, `summary`, `authors`, `published`, `pdf_id`, `pdf_name`, `doi`).
- `raw_results` — временный контейнер для результатов поиска (тексты)
- `url_sources` — набор URL найденных источников
- `research_loop_count` — счётчик итераций поиска/агрегации
- `running_summary` — агрегированная промежуточная суммаризация

---

## Узлы

- `call_model` — определяет **намерение пользователя (intent)** и формирует данные для передачи
- `store_memory` — сохраняет ключевые сообщения в долговременную память
- `analyze_node` — анализирует выбранную статью, используя релевантные фрагменты из Qdrant
- `arxiv_research` — выполняет поиск статей на arXiv по запросу
- `summarize_sources` — агрегирует найденные статьи в промежуточную суммаризацию
- `finalize_summary` — создает финальную суммаризацию с источниками

Граф соединяет узлы **по условным ребрам**, поток данных настраивается в зависимости от текущего состояния и намерения пользователя

---

## Организация памяти

### Долговременная

Сохраняет **загруженные статьи** и ключевые факты в векторном хранилище Qdrant

Хранится в **PostgreSQL** с TTL, интегрирована с StateGraph через `AsyncPostgresStore` и `AsyncPostgresSaver`

### Временная

Хранит результаты поиска и промежуточные суммаризации

Используется при цикличном поиске на arXiv и для генерации агрегированных ответов

### Контекст пользователя

Текущий запрос, намерение, выбранная статья (`current_article`) — в `PrivateState`

Все состояния объединены в структуру `OverallState`, которая хранит историю диалога (`messages`) и временные данные, сформированные при поиске статей

---

## Передача данных

**Между узлами**: через `state` графа

**LLM и память**: последние сообщения пользователя подтягиваются для контекста

**Результаты поиска** объединяются для дальшейшей суммаризации, затем вызывается LLM для генерации ответа

Используются Pydantic-модели (`Intent`, `Filter`, `ArticleInfo`) для типизации недетерминированного ответа LLM

---

## Мониторинг

Встроенный **логгер** фиксирует события в ключевых узлах

**Langfuse** используется для трассировки вызовов важных функций (`@traced`) и мониторинга потоков данных

TTL-сейвер следит за устаревшими записями в памяти и очищает их асинхронно

---

## Стек
`Langgraph` | `Langfuse` | `Pydantic` | `Qdrant` | `PostgreSQL (AsyncPostgresStore)` | `SpaCy` | `Streamlit`
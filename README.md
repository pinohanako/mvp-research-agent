# MVP агента для работы с научными текстами

Долговременная и временная память используется для хранения сообщений и структурированных данных, извлеченных из контекста по мере диалога; запросы перенаправляются с помощью LLM, настроена интеграция внешних источников для поиска научной информации. 

Ключевой компонент — **граф состояний**, который управляет обработкой пользовательских запросов. 

Граф позволяет обрабатывать данные по последовательным шагам: например, анализ статьи -> поиск дополнительных фрагментов -> обновление суммаризации

<p align="center">
  <img src="https://github.com/pinohanako/mvp-research-agent/blob/main/agent/docs/Prototype.png" alt="Прототип агента" width="1000"/>
</p>

---

## Намерения пользователя

При каждом запросе LLM классифицирует намерение на три категории:

- `search` — поиск статей на arXiv
- `analyze` — работа с уже загруженными статьями (анализ, суммаризация)
- `qa` — прямой ответ на вопрос или свободный текст

Для валидации JSON-ответа используется Pydantic-парсер и StructuredOutput

Провайдер API: OpenAI/Fireworks

---

## Как устроен `State`

Важнейшие поля:

- `messages` — список сообщений AnyMessage. Хранит историю диалога
- `query` — текущая строка запроса пользователя
- `intent` — распознанное текущее намерение: `"qa"` | `"search"` | `"analyze"`
- `current_article` — ArticleState (`title`, `summary`, `authors`, `published`, `pdf_id`, `pdf_name`, `doi`).
- `raw_results` — временный контейнер для результатов поиска (тексты)
- `url_sources` — набор URL найденных источников
- `research_loop_count` — счётчик итераций поиска/агрегации
- `running_summary` — агрегированная промежуточная суммаризация

Дополнительно: при необходимости в `state` добавляются ключи `pdf_id`, `pdf_url`, `pdf_name`, `title`, `authors`, `doi` — их формируют различные узлы

---

## Узлы

- `call_model` — определяет **намерение пользователя (intent)** и формирует данные для передачи
- `store_memory` — сохраняет ключевые сообщения в долговременную память
- `analyze_node` — анализирует выбранную статью, используя релевантные фрагменты из Qdrant
- `arxiv_research` — выполняет поиск статей на arXiv по запросу
- `summarize_sources` — агрегирует найденные статьи в промежуточную суммаризацию
- `finalize_summary` — создает финальную суммаризацию с источниками

Граф соединяет узлы **по условным ребрам**, поток данных настраивается в зависимости от текущего состояния и намерения пользователя

---

## Организация памяти

### Долговременная память

Сохраняет **подтвержденные статьи** и ключевые факты через `upsert_memory`

Хранится в **PostgreSQL** с TTL, интегрирована с StateGraph через `AsyncPostgresStore` и `AsyncPostgresSaver`

### Временная исследовательская память

Хранит результаты поиска и промежуточные суммаризации

Используется при цикличном поиске на arXiv (`research_loop_count`) и для генерации агрегированных ответов

### Контекст пользователя

Текущий запрос, намерение, выбранная статья (`current_article`) — в `PrivateState`

Все состояния объединены в структуру `OverallState`, которая хранит историю диалога (`messages`) и временные данные, сформированные при поиске статей

---

## Анализ и поиск

- **Анализ статьи** (`analyze_node`):

Получение embedding запроса через Jina

Поиск релевантных чанков в **Qdrant**

Конструирование промпта для LLM с учетом контекста статьи и найденных фрагментов

- **Поиск на arXiv** (`arxiv_research`):

Запрос к API arXiv

Извлечение найденных URL и сохранение текста в `raw_results`

Итеративная суммаризация через `summarize_sources` и `finalize_summary`

---

## Передача данных

**Между узлами**: через `state` графа

**LLM и память**: последние сообщения пользователя подтягиваются для контекста

**Результаты поиска** объединяются для дальшейшей суммаризации, затем вызывается LLM для генерации ответа

Все данные структурированы в Pydantic-моделях (`Intent`, `Filter`, `ArticleInfo`) для строгой типизации недетерминированного ответа LLM

---

## Мониторинг

Встроенный **логгер** фиксирует события в ключевых узлах

**Langfuse** используется для трассировки вызовов важных функций (`@traced`) и мониторинга потоков данных

TTL-сейвер следит за устаревшими записями в памяти и очищает их асинхронно

---

## Стек

`Langgraph` | `Langfuse` | `Pydantic` | `Qdrant` | `PostgreSQL (AsyncPostgresStore)` | `SpaCy` | `Streamlit`